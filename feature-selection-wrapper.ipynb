{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From https://www.kaggle.com/raviprakash438/wrapper-method-feature-selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset variables\n",
    "from IPython import get_ipython\n",
    "get_ipython().magic('reset -sf') \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import preprocessing # To get MinMax Scaler function\n",
    "\n",
    "# enable multiple outputs per cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data file\n",
    "df_train = pd.read_csv('./datasets/train_extracted.csv'\n",
    "                 , sep=',', encoding='utf-8')\n",
    "\n",
    "df_test = pd.read_csv('./datasets/test_extracted.csv'\n",
    "                 , sep=',', encoding='utf-8')\n",
    "\n",
    "df_valid = pd.read_csv('./datasets/valid_extracted.csv'\n",
    "                 , sep=',', encoding='utf-8')\n",
    "\n",
    "#just in case of NaN values\n",
    "df_train = df_train.dropna();\n",
    "df_test = df_test.dropna();\n",
    "df_valid = df_valid.dropna();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change label into binary classification\n",
    "# pick out target data\n",
    "df_train.label.loc[(df_train['label'] >= 0.5)] = 1;\n",
    "df_train.label.loc[(df_train['label'] < 0.5)] = 0;\n",
    "df_train_target = df_train['label']\n",
    "\n",
    "df_test.label.loc[(df_test['label'] >= 0.5)] = 1;\n",
    "df_test.label.loc[(df_test['label'] < 0.5)] = 0;\n",
    "df_test_target = df_test['label']\n",
    "\n",
    "df_valid.label.loc[(df_valid['label'] >= 0.5)] = 1;\n",
    "df_valid.label.loc[(df_valid['label'] < 0.5)] = 0;\n",
    "df_valid_target = df_valid['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick out feature data\n",
    "df_train_feature = df_train.drop(['label', 'statement'], axis=1)\n",
    "df_test_feature = df_test.drop(['label', 'statement'], axis=1)\n",
    "df_valid_feature = df_valid.drop(['label', 'statement'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove low variance data\n",
    "def variance_threshold(df, threshold=0.0):\n",
    "    selector = VarianceThreshold(threshold)\n",
    "    VT = selector.fit_transform(df)\n",
    "    return df[df.columns[selector.get_support(indices=True)]]\n",
    "\n",
    "# any column with a probability of having 0 variance above 0.8 will be eliminated\n",
    "# any column with variance lower than 0.16 will be eliminated\n",
    "df_train_feature = variance_threshold(df_train_feature, (.8 * (1 - .8)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the same low threshold features from test and valid set\n",
    "feature_removed = list(set(df_test_feature.columns).difference(df_train_feature.columns))\n",
    "df_test_feature = df_test_feature.drop(feature_removed, axis=1)\n",
    "df_valid_feature = df_valid_feature.drop(feature_removed, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the MinMaxScaler function\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "#standard_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# Scaling dataset keeping the columns name\n",
    "df_train_feature_scaled = pd.DataFrame(min_max_scaler.fit_transform(df_train_feature), columns = df_train_feature.columns)\n",
    "df_valid_feature_scaled = pd.DataFrame(min_max_scaler.fit_transform(df_valid_feature), columns = df_valid_feature.columns)\n",
    "df_test_feature_scaled = pd.DataFrame(min_max_scaler.fit_transform(df_test_feature), columns = df_test_feature.columns)\n",
    "#X_scaled = pd.DataFrame(standard_scaler.fit_transform(X), columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting  up data, seting 80% for train and 20% for test.\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df_train_feature_scaled, df_train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8165, 52), (2042, 52))"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find correlation between feature values\n",
    "def correlation(dataset,threshold):\n",
    "    col_corr=set() # set will contains unique values.\n",
    "    corr_matrix=dataset.corr() #finding the correlation between columns.\n",
    "    for i in range(len(corr_matrix.columns)): #number of columns\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i,j])>threshold: #checking the correlation between columns.\n",
    "                colName=corr_matrix.columns[i] #getting the column name\n",
    "                col_corr.add(colName) #adding the correlated column name heigher than threshold value.\n",
    "    return col_corr #returning set of column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlated columns: {'count_family', 'count_negate', 'count_quant', 'count_word', 'count_female', 'count_risk', 'count_space', 'count_sexual', 'count_cause', 'count_anx', 'count_health', 'count_adj', 'count_tentat', 'count_relativ', 'count_anger', 'count_auxverb', 'count_reward', 'count_male', 'count_swear', 'count_sad', 'count_leisure', 'count_social', 'count_affect', 'count_ingest', 'count_adverb', 'count_nonflu', 'count_assent', 'count_netspeak', 'count_achieve', 'count_insight', 'count_hear', 'count_death'}\n"
     ]
    }
   ],
   "source": [
    "# correlation variable (0.9) determines how closely correlated features have to be, to be discarded\n",
    "col=correlation(x_train,0.9) \n",
    "print('Correlated columns:',col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove correlated columns\n",
    "x_train.drop(columns=col,axis=1,inplace=True)\n",
    "x_test.drop(columns=col,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8165, 20), (2042, 20))"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  20 | elapsed:    2.3s remaining:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    2.5s finished\n",
      "\n",
      "[2020-04-01 06:49:38] Features: 1/10 -- score: 0.002133004579714792[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  19 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  19 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    0.2s finished\n",
      "\n",
      "[2020-04-01 06:49:38] Features: 2/10 -- score: 0.001243410703994341[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  18 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  18 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.3s finished\n",
      "\n",
      "[2020-04-01 06:49:39] Features: 3/10 -- score: -0.0016214446724374775[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  17 | elapsed:    0.0s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  17 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    0.3s finished\n",
      "\n",
      "[2020-04-01 06:49:39] Features: 4/10 -- score: -0.0044122598324672245[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  16 | elapsed:    0.1s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  16 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    0.3s finished\n",
      "\n",
      "[2020-04-01 06:49:40] Features: 5/10 -- score: -0.011588392694967364[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.4s finished\n",
      "\n",
      "[2020-04-01 06:49:40] Features: 6/10 -- score: -0.019286270754350854[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  14 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    0.4s finished\n",
      "\n",
      "[2020-04-01 06:49:41] Features: 7/10 -- score: -0.032974734975039645[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  13 | elapsed:    0.2s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  13 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    0.5s finished\n",
      "\n",
      "[2020-04-01 06:49:41] Features: 8/10 -- score: -0.05258671775576218[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  12 | elapsed:    0.2s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.5s finished\n",
      "\n",
      "[2020-04-01 06:49:42] Features: 9/10 -- score: -0.07458993040370676[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  11 | elapsed:    0.3s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    0.5s finished\n",
      "\n",
      "[2020-04-01 06:49:42] Features: 10/10 -- score: -0.07833579133458017"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequentialFeatureSelector(clone_estimator=True, cv=5,\n",
       "                          estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                          criterion='mse',\n",
       "                                                          max_depth=None,\n",
       "                                                          max_features='auto',\n",
       "                                                          max_leaf_nodes=None,\n",
       "                                                          min_impurity_decrease=0.0,\n",
       "                                                          min_impurity_split=None,\n",
       "                                                          min_samples_leaf=1,\n",
       "                                                          min_samples_split=2,\n",
       "                                                          min_weight_fraction_leaf=0.0,\n",
       "                                                          n_estimators='warn',\n",
       "                                                          n_jobs=None,\n",
       "                                                          oob_score=False,\n",
       "                                                          random_state=None,\n",
       "                                                          verbose=0,\n",
       "                                                          warm_start=False),\n",
       "                          fixed_features=None, floating=False, forward=True,\n",
       "                          k_features=10, n_jobs=-1, pre_dispatch='2*n_jobs',\n",
       "                          scoring='r2', verbose=2)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#k_features=10 (It will get top 10 features best suited for prediction)\n",
    "#forward=True (Forward feature selection model)\n",
    "#verbose=2 (It will show details output as shown below.)\n",
    "#cv=5 (Kfold cross valiation: it will split the training set in 5 set and 4 will be using for training the model and 1 will using as validation)\n",
    "#n_jobs=-1 (Number of cores it will use for execution.-1 means it will use all the cores of CPU for execution.)\n",
    "#scoring='r2'(R-squared is a statistical measure of how close the data are to the fitted regression line)\n",
    "model=sfs(RandomForestRegressor(),k_features=10,forward=True,verbose=2,cv=5,n_jobs=-1,scoring='r2')\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 2, 9, 10, 13, 14, 15, 17, 18)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the selected feature index.\n",
    "model.k_feature_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('num_-', 'num_\"', 'num_$', 'count_pronoun', 'count_they', 'count_interrog', 'count_discrep', 'count_certain', 'count_focuspast', 'count_money')\n"
     ]
    }
   ],
   "source": [
    "#Get the column name for the selected feature.\n",
    "forward_feature = model.k_feature_names_\n",
    "print(forward_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  20 | elapsed:    1.3s remaining:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    2.5s finished\n",
      "\n",
      "[2020-04-01 06:49:46] Features: 19/10 -- score: -0.1395618112201002[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  19 | elapsed:    1.2s remaining:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  19 | elapsed:    2.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    2.4s finished\n",
      "\n",
      "[2020-04-01 06:49:48] Features: 18/10 -- score: -0.13690560056805187[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  18 | elapsed:    1.2s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  18 | elapsed:    2.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    2.2s finished\n",
      "\n",
      "[2020-04-01 06:49:51] Features: 17/10 -- score: -0.13529070319328196[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  17 | elapsed:    1.1s remaining:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  17 | elapsed:    1.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    2.1s finished\n",
      "\n",
      "[2020-04-01 06:49:53] Features: 16/10 -- score: -0.13932725030561083[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  16 | elapsed:    0.9s remaining:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  16 | elapsed:    1.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    1.8s finished\n",
      "\n",
      "[2020-04-01 06:49:55] Features: 15/10 -- score: -0.135824336038488[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.9s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.6s finished\n",
      "\n",
      "[2020-04-01 06:49:57] Features: 14/10 -- score: -0.1379169167275034[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  14 | elapsed:    0.8s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    1.5s finished\n",
      "\n",
      "[2020-04-01 06:49:58] Features: 13/10 -- score: -0.13672703982204865[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  13 | elapsed:    0.8s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  13 | elapsed:    0.8s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    1.4s finished\n",
      "\n",
      "[2020-04-01 06:50:00] Features: 12/10 -- score: -0.14357939296395017[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  12 | elapsed:    0.7s remaining:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed:    0.8s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.8s finished\n",
      "\n",
      "[2020-04-01 06:50:01] Features: 11/10 -- score: -0.1446505913426694[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  11 | elapsed:    0.7s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    0.7s finished\n",
      "\n",
      "[2020-04-01 06:50:01] Features: 10/10 -- score: -0.15541781722400985"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequentialFeatureSelector(clone_estimator=True, cv=5,\n",
       "                          estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                          criterion='mse',\n",
       "                                                          max_depth=None,\n",
       "                                                          max_features='auto',\n",
       "                                                          max_leaf_nodes=None,\n",
       "                                                          min_impurity_decrease=0.0,\n",
       "                                                          min_impurity_split=None,\n",
       "                                                          min_samples_leaf=1,\n",
       "                                                          min_samples_split=2,\n",
       "                                                          min_weight_fraction_leaf=0.0,\n",
       "                                                          n_estimators='warn',\n",
       "                                                          n_jobs=None,\n",
       "                                                          oob_score=False,\n",
       "                                                          random_state=None,\n",
       "                                                          verbose=0,\n",
       "                                                          warm_start=False),\n",
       "                          fixed_features=None, floating=False, forward=False,\n",
       "                          k_features=10, n_jobs=-1, pre_dispatch='2*n_jobs',\n",
       "                          scoring='r2', verbose=2)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#k_features=10 (It will get top 10 features best suited for prediction)\n",
    "#forward=False (Backward feature selection model)\n",
    "#verbose=2 (It will show details output as shown below.)\n",
    "#cv=5 (Kfold cross valiation: it will split the training set in 5 set and 4 will be using for training the model and 1 will using as validation)\n",
    "#n_jobs=-1 (Number of cores it will use for execution.-1 means it will use all the cores of CPU for execution.)\n",
    "#scoring='r2'(R-squared is a statistical measure of how close the data are to the fitted regression line)\n",
    "backwardModel=sfs(RandomForestRegressor(),k_features=10,forward=False,verbose=2,cv=5,n_jobs=-1,scoring='r2')\n",
    "#We will convert our training data into numpy array. If we will not convert it, model is not able to read some of the column names. \n",
    "backwardModel.fit(np.array(x_train),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 6, 7, 8, 10, 12, 13, 14, 16)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the selected feature index.\n",
    "backwardModel.k_feature_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['num_,', 'num_.', 'count_char_per_word', 'count_unique',\n",
      "       'count_uppercase', 'count_they', 'count_compare', 'count_interrog',\n",
      "       'count_discrep', 'count_affiliation'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Get the column name for the selected feature.\n",
    "backward_feature = x_train.columns[list(backwardModel.k_feature_idx_)]\n",
    "print(backward_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exhaustive Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 638/638"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExhaustiveFeatureSelector(clone_estimator=True, cv=5,\n",
       "                          estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                          criterion='mse',\n",
       "                                                          max_depth=None,\n",
       "                                                          max_features='auto',\n",
       "                                                          max_leaf_nodes=None,\n",
       "                                                          min_impurity_decrease=0.0,\n",
       "                                                          min_impurity_split=None,\n",
       "                                                          min_samples_leaf=1,\n",
       "                                                          min_samples_split=2,\n",
       "                                                          min_weight_fraction_leaf=0.0,\n",
       "                                                          n_estimators='warn',\n",
       "                                                          n_jobs=None,\n",
       "                                                          oob_score=False,\n",
       "                                                          random_state=None,\n",
       "                                                          verbose=0,\n",
       "                                                          warm_start=False),\n",
       "                          max_features=10, min_features=5, n_jobs=-1,\n",
       "                          pre_dispatch='2*n_jobs', print_progress=True,\n",
       "                          scoring='r2')"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as efs\n",
    "#min_features=1 (minimum number of feature)\n",
    "#max_features=5 (maximum number of feature)\n",
    "#n_jobs=-1 (Number of cores it will use for execution.-1 means it will use all the cores of CPU for execution.)\n",
    "#scoring='r2'(R-squared is a statistical measure of how close the data are to the fitted regression line)\n",
    "emodel=efs(RandomForestRegressor(),min_features=5,max_features=10,scoring='r2',n_jobs=-1)\n",
    "#Lets take only 10 features which we got from backward feature selection.\n",
    "miniData=x_train[x_train.columns[list(backwardModel.k_feature_idx_)]]\n",
    "\n",
    "emodel.fit(np.array(miniData),y_train)\n",
    "#If you see below the model creates 637 feature combinations from 10 features.Thats why its computationally very expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 6, 7, 8, 9)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the selected feature index.\n",
    "emodel.best_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['num_,', 'count_compare', 'count_interrog', 'count_discrep',\n",
      "       'count_affiliation'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Get the column name for the selected feature.\n",
    "exhaustive_feature = miniData.columns[list(emodel.best_idx_)]\n",
    "print(exhaustive_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('num_-', 'num_\"', 'num_$', 'count_pronoun', 'count_they', 'count_interrog', 'count_discrep', 'count_certain', 'count_focuspast', 'count_money')\n"
     ]
    }
   ],
   "source": [
    "print(forward_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['num_,', 'num_.', 'count_char_per_word', 'count_unique',\n",
      "       'count_uppercase', 'count_they', 'count_compare', 'count_interrog',\n",
      "       'count_discrep', 'count_affiliation'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(backward_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['count_interrog', 'count_discrep', 'count_they']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(forward_feature).intersection(backward_feature))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
