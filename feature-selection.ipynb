{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources: https://www.kaggle.com/ferneutron/feature-extraction-with-different-methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # To handle the data set.\n",
    "import seaborn as sb # To display visualizations.\n",
    "import matplotlib.pyplot as plt # To plot\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier # Random Forest\n",
    "from sklearn.metrics import confusion_matrix # To calculate the confusion matrix\n",
    "from sklearn.metrics import accuracy_score # To calculate the score\n",
    "from sklearn.feature_selection import SelectKBest # Univariate Feature Selection\n",
    "from sklearn.feature_selection import chi2 # To apply Univariate Feature Selection\n",
    "from sklearn.feature_selection import RFE # Recursive Feature Selection\n",
    "from sklearn.feature_selection import RFECV # Recursive Feature Selection with Cross Validation\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA # To apply PCA\n",
    "from sklearn import preprocessing # To get MinMax Scaler function\n",
    "\n",
    "# To plot inline\n",
    "%matplotlib inline\n",
    "\n",
    "# enable multiple outputs per cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# hide warnings\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/feature_extracted.csv'\n",
    "                 , sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change label into binary classification\n",
    "df.label.loc[(df['label'] >= 0.5)] = 1\n",
    "df.label.loc[(df['label'] < 0.5)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide into training and test set\n",
    "df = shuffle(df, random_state=123)\n",
    "#df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "X = df.copy().drop(['statement','label'], axis=1)\n",
    "X = X.fillna(0)\n",
    "Y = df.copy()['label']\n",
    "Y = Y.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12741, 92)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(12741, 89)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove low variance data\n",
    "sel_variance_threshold = VarianceThreshold()\n",
    "X = sel_variance_threshold.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-190-27122b74571b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmin_max_scaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Scaling dataset keeping the columns name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_max_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "# Initializing the MinMaxScaler function\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# Scaling dataset keeping the columns name\n",
    "X_scaled = pd.DataFrame(min_max_scaler.fit_transform(X), columns = X.columns, index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting  up data, seting 75% for train and 25% for test.\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, Y, test_size=0.25, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate selection (chi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SelectKBest function\n",
    "UnivariateFeatureSelection = SelectKBest(chi2, k=10).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a dict to visualize which features were selected with the highest score\n",
    "feature_dict = {key:value for (key, value) in zip(\n",
    "    UnivariateFeatureSelection.scores_, x_train.columns)}\n",
    "sorted(feature_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_k_best = UnivariateFeatureSelection.transform(x_train)\n",
    "x_test_k_best = UnivariateFeatureSelection.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandForest_K_best = RandomForestClassifier()      \n",
    "RandForest_K_best = RandForest_K_best.fit(x_train_k_best, y_train)\n",
    "y_pred = RandForest_K_best.predict(x_test_k_best)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confMatrix = confusion_matrix(y_test, y_pred)\n",
    "sb.heatmap(confMatrix, annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SelectKBest function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Random Forest Classifier\n",
    "RandForest_RFE = RandomForestClassifier() \n",
    "# Initializing the RFE object, one of the most important arguments is the estimator, in this case is RandomForest\n",
    "rfe = RFE(estimator=RandForest_RFE, n_features_to_select=5, step=1)\n",
    "# Fit the origial dataset\n",
    "rfe = rfe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best features chosen by RFE: \\n\")\n",
    "for i in x_train.columns[rfe.support_]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_RFE = rfe.transform(x_train)\n",
    "x_test_RFE = rfe.transform(x_test)\n",
    "RandForest_RFE = RandForest_RFE.fit(x_train_RFE, y_train)\n",
    "y_pred = RandForest_RFE.predict(x_test_RFE)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confMatrix = confusion_matrix(y_test, y_pred)\n",
    "sb.heatmap(confMatrix, annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest Classifier\n",
    "RandForest_RFECV = RandomForestClassifier() \n",
    "# Initialize the RFECV function setting 3-fold cross validation\n",
    "rfecv = RFECV(estimator=RandForest_RFECV, step=1, cv=3, scoring='accuracy')\n",
    "# Fit data\n",
    "rfecv = rfecv.fit(x_train, y_train)\n",
    "\n",
    "print('Best number of features :', rfecv.n_features_)\n",
    "print('Features :\\n')\n",
    "for i in x_train.columns[rfecv.support_]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlabel(\"Number of Features\")\n",
    "plt.ylabel(\"Score of Selected Features\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree based Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest Classifier\n",
    "RandForest_Tree = RandomForestClassifier()  \n",
    "# Fit the random forest with the original data\n",
    "RandForest_Tree = RandForest_Tree.fit(x_train, y_train)\n",
    "# Getting the relevance between features\n",
    "relevants = RandForest_Tree.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the tree based on importance for the random forest classifier and indexing it\n",
    "std = np.std([tree.feature_importances_ for tree in RandForest_Tree.estimators_], axis=0)\n",
    "indices = np.argsort(relevants)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printting the ranking of importance\n",
    "print(\"Feature Rank:\")\n",
    "\n",
    "for i in range(x_train.shape[1]):\n",
    "    print(\"%d. Feature %d (%f)\" \n",
    "          % (i + 1, indices[i], relevants[indices[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the feature importances\n",
    "plt.figure(1, figsize=(15, 5))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.bar(range(x_train.shape[1]), relevants[indices], color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(x_train.shape[1]), x_train.columns[indices],rotation=90)\n",
    "plt.xlim([-1, x_train.shape[1]])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction through PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing PCA and fitting\n",
    "pca = PCA()\n",
    "pca.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting to visualize the best number of elements\n",
    "plt.figure(1, figsize=(9, 8))\n",
    "plt.clf()\n",
    "plt.axes([.2, .2, .7, .7])\n",
    "plt.plot(pca.explained_variance_ratio_, linewidth=2)\n",
    "plt.axis('tight')\n",
    "plt.xlabel('Number of Feautres')\n",
    "plt.ylabel('Variance Ratio')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
