{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Evaluation\n",
    "\n",
    "This program will perform feature extraction, feature analyzation and machine learning for fake news detections:\n",
    "1. Gather the news data from NewsAPI.org\n",
    "2. Extract the individual features from news data\n",
    "3. Extract the relational features from news data\n",
    "4. Feature analyzation\n",
    "5. Test with machine learning\n",
    "\n",
    "Date: Feb 26th, 2020</br>\n",
    "Programmed by: Sasung Kim, Christophe Liu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.output_scroll { height: 50em; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import required modules\n",
    "# For NewsAPI\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "# For Individual Feature Extraction \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# For Relational Feature Extraction\n",
    "from statistics import mean\n",
    "import math\n",
    "\n",
    "# For feature analyzation\n",
    "#enable multiple outputs per cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# increase size of output window\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 50em; }</style>\"))\n",
    "\n",
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "# For machine learning\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Modeling\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Cross-validation\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Saving\n",
    "import joblib\n",
    "from joblib import dump, load\n",
    "\n",
    "#feature selection\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, f_classif\n",
    "from sklearn.feature_selection import chi2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Scrap API\n",
    "\n",
    "<h4>This program scraps a news about specific topic from newsapi.org API.</h4>\n",
    "To change topic (or select topic), change q = '' part\n",
    "To get specific news domain, use domains = '<news domain url>&'\n",
    "Use page=#& to get more results\n",
    "\n",
    "Data includes: Author, title, description, url, content, publishing date, source ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_api(topic, number, source, reliability):\n",
    "    # List creation\n",
    "    source_id = []\n",
    "    author = []\n",
    "    title = []\n",
    "    description = []\n",
    "    url = []\n",
    "    content = []\n",
    "    pub_date = []\n",
    "    rel = []\n",
    "\n",
    "    #set the reliability list by user input\n",
    "    if reliability is 1:\n",
    "        rel = np.ones(number)\n",
    "    elif reliability is 0:\n",
    "        rel = np.zeros(number)\n",
    "    \n",
    "    # Read 100 news articles about coronavirus (20 articles per each page, 5 pages) and parse each data into corresponding lists\n",
    "    for i in range(1, int((number/20)+1)):\n",
    "\n",
    "        # News extraction\n",
    "        news_url = ('https://newsapi.org/v2/everything?'\n",
    "                f'domains={source}&'\n",
    "                'pageSize=20'\n",
    "                f'q={topic}&'\n",
    "               f'page={i}&'\n",
    "               'sortBy=popularity&'\n",
    "               'apiKey=963417ea47cd41199fcbae1e1189b85b')\n",
    "\n",
    "        news = requests.get(news_url)\n",
    "        \n",
    "        \n",
    "        size = news.json()['totalResults']\n",
    "        \n",
    "        print(size)\n",
    "        \n",
    "        if(number > size):\n",
    "            rel.resize(size)\n",
    "        \n",
    "        for elements in news.json()['articles']:\n",
    "            source_id.append(elements['source']['id'])\n",
    "            author.append(elements['author'])\n",
    "            title.append(elements['title'])\n",
    "            description.append(elements['description'])\n",
    "            url.append(elements['url'])\n",
    "            content.append(elements['content'])\n",
    "            pub_date.append(elements['publishedAt'])\n",
    "\n",
    "            # *For CNN Only: check if the content is video and data does not related to the article\n",
    "            #if (elements['content'] == 'None' or elements['content'] == \"Chat with us in Facebook Messenger. Find out what's happening in the world as it unfolds.\"):\n",
    "            #    pass\n",
    "                #print(elements['description'])\n",
    "            #else:\n",
    "                #print (elements['content'])\n",
    "            #    pass\n",
    "    \n",
    "    # Test for parsed data\n",
    "    news_info = pd.DataFrame()\n",
    "    news_info['source_id'] = source_id\n",
    "    news_info['author'] = author\n",
    "    news_info['title'] = title\n",
    "    news_info['description'] = description\n",
    "    news_info['url'] = url\n",
    "    news_info['content'] = content\n",
    "    news_info['published_date'] = pub_date\n",
    "    news_info['label'] = rel\n",
    "    return news_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Feature Extraction\n",
    "\n",
    "This portion of code is for individual feature extraction from given data.\n",
    "\n",
    "At the beginning, the program grab the description from the given dataset and extract the features from the news contents.\n",
    "Then, it output extracted data and features as dataframe.\n",
    "\n",
    "Features used in this program are:\n",
    "1. Number of Characters\n",
    "2. Number of Words\n",
    "3. Number of Verbs\n",
    "4. Number of Nouns\n",
    "5. Number of Sentence\n",
    "6. Average Number of Words per Sentence\n",
    "7. Average Number of Characters in Words\n",
    "8. Number of Question Marks (?)\n",
    "9. Percentage of Subjective Verbs\n",
    "10. Percentage of Passive Voice\n",
    "11. Percentage of Positive Words\n",
    "12. Percentage of Negative Words\n",
    "13. Lexical Diversity: Unique Words or Terms\n",
    "14. Typographical Error Ration: Misspelled Words\n",
    "15. Causation Terms\n",
    "16. Percentage of generalizing terms\n",
    "17. Percentage of numbers and quantifiers\n",
    "18. 1st person pronouns\n",
    "19. 2nd and 3rd person pronouns\n",
    "20. Exclusive terms\n",
    "21. Number of exclamation marks (!)\n",
    "22. Lexical\n",
    "23. Singular pronouns (1st person)\n",
    "24. Group ref pronouns (1st person)\n",
    "25. 2nd and 3rd pronouns\n",
    "\n",
    "How to use: First, place positive-words.txt and negative-words.txt files in word_sentiment folder and put\n",
    "            .csv dataset in liar_dataset folder in datasets folder and put the name of the .csv file\n",
    "            in argument space of setup_data function. Next, use feature_extraction function with the result of\n",
    "            setup_data function to extract the features and save the data in the desired file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the lists of the words that used for feature extraction\n",
    "\n",
    "positive_list = list()\n",
    "negative_list = list()\n",
    "\n",
    "# Gather the positive and negative word lists from the text file\n",
    "with open('./word_sentiment/positive-words.txt') as p:\n",
    "    for line in p:\n",
    "        val = line.split()\n",
    "        for ele in val:\n",
    "            positive_list.append(ele)\n",
    "\n",
    "with open('./word_sentiment/negative-words.txt') as n:\n",
    "    for line in n:\n",
    "        val = line.split()\n",
    "        for ele in val:\n",
    "            negative_list.append(ele)\n",
    "\n",
    "subjective_list = list(['am', 'are', 'is', 'was', 'were', 'be', 'been'])\n",
    "causation_list = list(['led to', 'because', 'cause', 'caused', 'reason', 'explanation', 'so'])\n",
    "\n",
    "exclusive_list = list(['except', 'else', 'besides', 'without', 'exclude', 'other than'])\n",
    "generalizing_list = list(['all', 'none', 'most', 'many', 'always', 'everyone','never',\n",
    "                          'some','usually','few','seldom','generally','general','overall'])\n",
    "pronoun_1st_list = list(['I','we'])\n",
    "pronoun_2nd3rd_list = list(['you','your','yours','he','she','it','him','her','his','her','its','hers','They','them','theirs','their'])\n",
    "\n",
    "SPronoun_list = list(['I', 'mine','my','me'])\n",
    "GPronoun_list = list(['we','ours','our','us'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the dataset, isolate the required data (statement and label in this program) and return as pandas Series\n",
    "# If the user needs the required data as a file, uncomment def with new_file as argument and comment the other one\n",
    "\n",
    "def read_data(fileName):\n",
    "    \n",
    "    header = [\"ID\", \"label\", \"description\", 'subject', 'speaker', 'speaker_job', 'state_info', 'party_aff', 'barely_true', 'false', 'half_true', 'mostly_true', 'pants_on_fire', 'context']\n",
    "    data = pd.read_csv(f\"./datasets/liar_dataset/{fileName}\", delimiter = '\\t', names = header, encoding = 'unicode_escape')\n",
    "    \n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "    description = data['description']\n",
    "    label = data['label']\n",
    "    topic = data['subject']\n",
    "\n",
    "    label = label.replace('TRUE', 1)\n",
    "    label = label.replace('mostly-true', 1)\n",
    "    label = label.replace('half-true', 1)\n",
    "    label = label.replace('barely-true', 0)\n",
    "    label = label.replace('FALSE', 0)\n",
    "    label = label.replace('pants-fire', 0)\n",
    "\n",
    "    result['description'] = description\n",
    "    result['label'] = label\n",
    "    result['topic'] = topic\n",
    "    \n",
    "    return result\n",
    "\n",
    "#def setup_data(file_name, new_file):\n",
    "def setup_data(fileName, subject, rel):\n",
    "    \n",
    "    news_info = pickle.load(open(f'./news_data/{fileName}', 'rb'))[subject]\n",
    "    \n",
    "    size = len(news_info)\n",
    "    \n",
    "    if (rel is 1):\n",
    "        label = np.ones(size)\n",
    "    elif (rel is 0):\n",
    "        label = np.zeros(size)\n",
    "    \n",
    "    news_info['label'] = label\n",
    "    \n",
    "    # drop the null values (if both content and description are null)\n",
    "    data = news_info.dropna(how = 'any')\n",
    "    for i in range(len(data)):\n",
    "        try:\n",
    "            if (len(news_info['description'][i]) is 0):\n",
    "                data = data.drop(i)\n",
    "        except:\n",
    "            pass\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: String ('str')\n",
    "# Description: Tockenize and tag input with nltk universal tag\n",
    "# Return: tags of each tockens - String ('tagged')\n",
    "# Tockenize and tag input String with nltk universal tag and return the tags for each words in the String\n",
    "\n",
    "def tagging_univ(str):\n",
    "    try:\n",
    "        text = nltk.word_tokenize(str)\n",
    "    except:\n",
    "        print(str)\n",
    "        print(type(str))\n",
    "    tagged = nltk.pos_tag(text, tagset='universal')\n",
    "    return tagged\n",
    "\n",
    "# Input: String('str')\n",
    "# Description: Tockenize and tag input with nltk non-universal tag\n",
    "# Return: tags of each tockens - String ('tagged')\n",
    "\n",
    "def tagging_nuniv(str):\n",
    "    text = nltk.word_tokenize(str)\n",
    "    tagged = nltk.pos_tag(text)\n",
    "    return tagged\n",
    "\n",
    "# Input: String('str')\n",
    "# Description: Count the number of characters in input\n",
    "# Return: Character count - int ('count')\n",
    "\n",
    "def count_char(str):\n",
    "    no_space = str.replace(\" \", \"\")\n",
    "    count = len(no_space)\n",
    "    return count\n",
    "\n",
    "# Input: String('str')\n",
    "# Description: Count the number of words in input\n",
    "# Return: Word count - int ('count')\n",
    "\n",
    "def count_word(str):\n",
    "    count = len(str.split())\n",
    "    return count\n",
    "\n",
    "# Input: String ('str')\n",
    "# Description: Count the number of sentences by counting number of period(.)\n",
    "# Return: Sentence count - int ('sentence')\n",
    "\n",
    "def count_sent(str):\n",
    "    sentence = len(str.split('.'))\n",
    "    return sentence\n",
    "\n",
    "# Input: String ('states')\n",
    "# Description: Count the number of characters in each word in input and average the number of characters per word\n",
    "# Return: Average number of characters: float ('avg')\n",
    "\n",
    "def count_char_per_word(states):\n",
    "    word = []\n",
    "    word.append(states.split())\n",
    "    char_per_word = list()\n",
    "    for elements in word:\n",
    "        for char in elements:\n",
    "            c_in_w_count = len(char)\n",
    "            char_per_word.append(c_in_w_count)\n",
    "    # char_per_word_list.append()\n",
    "    avg = sum(char_per_word) / len(char_per_word)\n",
    "    char_per_word.clear()\n",
    "    return avg\n",
    "\n",
    "# Input: String ('tagged'), String ('tag'), count ('int')\n",
    "# Description: Count the number of specified tags ('tag') from the input\n",
    "# Return: Count of specified tag - int ('int')\n",
    "\n",
    "def check_tag(check, tag, count):\n",
    "    if check == tag:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "# Input: String ('tagged'), list ('list'), int ('int')\n",
    "# Description: Count the number of common words between input String and input list\n",
    "# Return: Count of common words - int ('int')\n",
    "# Count and return the number of words that is included in the given list in the statement\n",
    "\n",
    "def check_common(state, list, count):\n",
    "    #for ele in list:\n",
    "    #    count = tagged.count(ele)\n",
    "    #return count\n",
    "    for elements in list:\n",
    "        for words in state.split():\n",
    "            if words == elements:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "# Input: String ('word'), String ('tag'), list ('subjective_list'), int ('sent_count')\n",
    "# Description: Count the number of passive voice and avarge it from number of sentence (sent_count)\n",
    "# Return: Average of passive voiced sentences - float ('result')\n",
    "\n",
    "def count_passive(word, tag, subjective_list, sent_count):\n",
    "    percent_sub = 0\n",
    "    counter = 0\n",
    "    for ele in subjective_list:\n",
    "        if (word.count(ele) > 0 and tag == \"VBN\"):\n",
    "            counter += 1\n",
    "    result = counter / sent_count * 100\n",
    "    return result\n",
    "\n",
    "# Input: String ('states')\n",
    "# Description: Count the words that introduced only once in input\n",
    "# Return: Count of unique words - int ('unique_count')\n",
    "\n",
    "def count_unique(states):\n",
    "    words = states.split(' ')\n",
    "    c = Counter(words)\n",
    "    unique = [w for w in words if c[w] == 1]\n",
    "    unique_counter = len(unique)\n",
    "    return unique_counter\n",
    "\n",
    "# Calvin\n",
    "def avg_char(states):\n",
    "    word.append(states.split())\n",
    "    char_per_word = list()\n",
    "    for elements in word:\n",
    "        for char in elements:\n",
    "            c_in_w_count = len(char)\n",
    "            char_per_word.append(c_in_w_count)\n",
    "    word.clear()\n",
    "    avg = sum(char_per_word)/len(char_per_word)\n",
    "    char_per_word.clear()\n",
    "    return avg\n",
    "\n",
    "\n",
    "# Input: panda Series ('data'), String ('save_file_name')\n",
    "# Description: First, this function creates lists for each features and extract the features using statements in dataset and\n",
    "#              above functions. Next, it creates a large pandas Series that consist of news contents, labels and extracted\n",
    "#              features. Finally, it save the final pandas Series in a file to make easier to examine the result (do not need\n",
    "#              to rerun the program or change the code to check raw data)\n",
    "# Return: Pandas Series consist of news contents, labels and extracted features count - pandas Series ('new')\n",
    "\n",
    "def feature_extract(data):\n",
    "    # define the news contents and labels from the dataset\n",
    "    state = data['description']\n",
    "    label = data['label']\n",
    "    \n",
    "    # Create a dataframe that will store every feature values\n",
    "    ind_feature = pd.DataFrame()\n",
    "\n",
    "    # create lists for storing the counters\n",
    "    char_count_list = list()\n",
    "    word_count_list = list()\n",
    "    verb_count_list = list()\n",
    "    noun_count_list = list()\n",
    "    sent_count_list = list()\n",
    "    words_per_sent_list = list()\n",
    "    char_per_word_list = list()\n",
    "    quest_count_list = list()\n",
    "    sub_count_list = list()\n",
    "    pass_count_list = list()\n",
    "    pos_count_list = list()\n",
    "    neg_count_list = list()\n",
    "    unique_count_list = list()\n",
    "    typo_count_list = list()\n",
    "    cause_count_list = list()\n",
    "    \n",
    "    # Calvin\n",
    "    gene_count_list = list()\n",
    "    num_count_list = list()\n",
    "    pron_1st_count_list = list()\n",
    "    pron_2nd3rd_count_list = list()\n",
    "    exclu_count_list = list()\n",
    "    \n",
    "    # Andrew\n",
    "    exclam_list = list()\n",
    "    lex_list = list()\n",
    "    singlulars_list = list()\n",
    "    group_list = list()\n",
    "    other_list = list()\n",
    "\n",
    "\n",
    "    word = list()\n",
    "\n",
    "    #print(type(state))\n",
    "    # loop for checking each new contents in dataset\n",
    "    for states in state:\n",
    "\n",
    "        #print(states)\n",
    "        # reset the counters for each news contents\n",
    "        w_in_s_count = 0\n",
    "        c_in_w_count = 0\n",
    "        verb_count = 0\n",
    "        noun_count = 0\n",
    "        sub_count = 0\n",
    "        pos_count = 0\n",
    "        neg_count = 0\n",
    "        percent_pos = 0\n",
    "        percent_neg = 0\n",
    "        unique_count = 0\n",
    "        sent_counts = 0\n",
    "        typo_count = 0\n",
    "        cause_count = 0\n",
    "        gene_count = 0\n",
    "        pron_1st_count = 0\n",
    "        pron_count = 0\n",
    "        exclu_count = 0\n",
    "        SelfP = 0\n",
    "        count_prongroup = 0\n",
    "        group = 0\n",
    "        other = 0\n",
    "        num= 0\n",
    "        \n",
    "        # Tockenization and tagging with nltk universal and non-universal tag systems (tagged = universal, tagged_nu = non-universal)\n",
    "        tagged = tagging_univ(states)\n",
    "        tagged_nu = tagging_nuniv(states)\n",
    "\n",
    "        # Check the tags of each news contents\n",
    "        # print(tagged)\n",
    "        # print(tagged_nu)\n",
    "\n",
    "        # Extract the features and append the results in the list. Commented lines with print() functions are for testing\n",
    "\n",
    "        # 1. Number of Characters\n",
    "        char_count = count_char(states)\n",
    "        char_count_list.append(char_count)\n",
    "\n",
    "        # 2. Nubmer of Words\n",
    "        word_count = count_word(states)\n",
    "        word_count_list.append(word_count)\n",
    "\n",
    "        # 3. Number of Verbs\n",
    "        for tag in tagged:\n",
    "            verb_count = check_tag(tag[1], 'VERB', verb_count)\n",
    "        if verb_count == 0:\n",
    "            verb_count = 1\n",
    "        verb_count_list.append(verb_count)\n",
    "\n",
    "        # 4. Number of Nouns\n",
    "        for tag in tagged:\n",
    "            noun_count = check_tag(tag[1], 'NOUN', noun_count)\n",
    "        noun_count_list.append(noun_count)\n",
    "        # print(noun_count)\n",
    "\n",
    "        # 5. Number of Sentence\n",
    "        statement = states.replace('...', '.')\n",
    "        sent_count = count_sent(statement)\n",
    "        sent_count_list.append(sent_count)\n",
    "        # print(sent_count)\n",
    "\n",
    "        # 6. Average number of words per sentence\n",
    "        sent = [len(l.split()) for l in re.split(r'[?!.]', statement) if l.strip()]\n",
    "        if len(sent) == 0:\n",
    "            sent.append(word_count)\n",
    "        w_in_s_count = (sum(sent) / len(sent))\n",
    "        words_per_sent_list.append(w_in_s_count)\n",
    "        # print(w_in_s_count)\n",
    "\n",
    "        # 7. Average number of characters per word\n",
    "        c_in_w_count = count_char_per_word(states)\n",
    "        char_per_word_list.append(c_in_w_count)\n",
    "        # print(c_in_w_count)\n",
    "\n",
    "        # 8. Number of question marks\n",
    "        quest_count = states.count(\"?\")\n",
    "        quest_count_list.append(quest_count)\n",
    "\n",
    "        # 9. Percentage of subjective verbs - am/are/is/etc\n",
    "        sub_count = check_common(states, subjective_list, sub_count)\n",
    "        if (verb_count > 0):\n",
    "            percent_sub = sub_count / verb_count * 100\n",
    "        sub_count_list.append(percent_sub)\n",
    "\n",
    "        # 10. Percentage of passive voice - am/are/is && past participate\n",
    "        for tag in tagged_nu:\n",
    "            passive_percent = count_passive(tag[0], tag[1], subjective_list, sent_count)\n",
    "        pass_count_list.append(passive_percent)\n",
    "\n",
    "        # 11. Percentage of positive words\n",
    "        for tag in tagged:\n",
    "            pos_count = check_common(tag[0], positive_list, pos_count)\n",
    "            percent_pos = pos_count / word_count * 100\n",
    "        pos_count_list.append(percent_pos)\n",
    "\n",
    "        # 12. Percentage of negative words\n",
    "        for tag in tagged:\n",
    "            neg_count = check_common(tag[0], negative_list, neg_count)\n",
    "            percent_neg = neg_count / word_count * 100\n",
    "        neg_count_list.append(percent_neg)\n",
    "\n",
    "        # 13. Lexical diversity: unique words or terms\n",
    "        unique_count = count_unique(states)\n",
    "        unique_count_list.append(unique_count)\n",
    "\n",
    "        # 14. Typographical error ratio: misspelled words\n",
    "        for tag in tagged:\n",
    "            typo_count = check_tag(tag[1], 'X', typo_count)\n",
    "        typo_count_list.append(typo_count)\n",
    "\n",
    "        # 15. Causation terms\n",
    "        cause_count = check_common(states, causation_list, cause_count)\n",
    "        cause_count_list.append(cause_count)\n",
    "\n",
    "        # 16. Percentage of generalizing terms\n",
    "        gene_count = check_common(states, generalizing_list, gene_count)\n",
    "        gene_count_list.append(gene_count)\n",
    "        \n",
    "        # 17. Percentage of numbers and quantifiers\n",
    "        for tag in tagged:\n",
    "            num = check_tag(tag[1], 'NUM', num)\n",
    "        num_count_list.append(num)\n",
    "\n",
    "        # 18. 1st person pronouns\n",
    "        pron_1st_count = check_common(states, pronoun_1st_list, pron_1st_count)\n",
    "        pron_1st_count_list.append(pron_1st_count)\n",
    "   \n",
    "        # 19. 2nd and 3rd person pronouns\n",
    "        pron_count = check_common(states, pronoun_2nd3rd_list, pron_count)\n",
    "        pron_2nd3rd_count_list.append(pron_count)\n",
    "\n",
    "        # 20. Exclusive terms\n",
    "        exclu_count = check_common(states, exclusive_list, exclu_count)\n",
    "        exclu_count_list.append(exclu_count)\n",
    "        \n",
    "        # 21. # of exclamation marks\n",
    "        exclam_count = states.count(\"!\")\n",
    "        exclam_list.append(exclam_count)\n",
    "        \n",
    "        # 22. lexical \n",
    "        unique_count = count_unique(states)\n",
    "        lex_list.append(unique_count)\n",
    "        \n",
    "        # 23. singlular pronouns (1st person)\n",
    "        SelfP = check_common(states, SPronoun_list, SelfP)\n",
    "        singlulars_list.append(SelfP)\n",
    "        \n",
    "        # 24. Group ref pronouns (1st person)\n",
    "        group = check_common(states, GPronoun_list, group)\n",
    "        group_list.append(group)\n",
    "        \n",
    "        # 25. 2nd 3rd pronouns\n",
    "        other = check_common(states, pronoun_2nd3rd_list, other)\n",
    "        other_list.append(other)\n",
    "        \n",
    "\n",
    "    # Put the data into a dataframe\n",
    "        \n",
    "    ind_feature['Statement'] = state\n",
    "    ind_feature['Label'] = label\n",
    "    ind_feature['# of Characters'] = char_count_list\n",
    "    ind_feature['# of Words'] = word_count_list\n",
    "    ind_feature['# of Verbs'] = verb_count_list\n",
    "    ind_feature['# of Noun'] = noun_count_list\n",
    "    ind_feature['# of Sentence'] = sent_count_list\n",
    "    ind_feature['Average # of Words per Sentence'] = words_per_sent_list\n",
    "    ind_feature['Average # of Characters per Words'] = char_per_word_list\n",
    "    ind_feature['# of Question Marks'] = quest_count_list\n",
    "    ind_feature['% of Subjective Verbs'] = sub_count_list\n",
    "    ind_feature['% of Passive Voice'] = pass_count_list\n",
    "    ind_feature['% of Positive Words'] = pos_count_list\n",
    "    ind_feature['% of Negative Words'] = neg_count_list\n",
    "    ind_feature['# of Unique Wrods/Terms'] = unique_count_list\n",
    "    ind_feature['# of Misspelled Words'] = typo_count_list\n",
    "    ind_feature['# of Causation Terms'] = cause_count_list\n",
    "    ind_feature['% of generalizing terms'] = gene_count_list\n",
    "    ind_feature['% of # and quantifiers'] = num_count_list\n",
    "    ind_feature['1st person pronouns'] = pron_1st_count_list\n",
    "    ind_feature['2nd and 3rd person pronouns'] = pron_2nd3rd_count_list\n",
    "    ind_feature['Exclusive term'] = exclu_count_list\n",
    "    ind_feature['# of exclamation marks'] = exclam_list\n",
    "    ind_feature['Lexical'] = lex_list\n",
    "    ind_feature['Singular pronouns(1st person)'] = singlulars_list\n",
    "    ind_feature['Group ref pronouns(1st person)'] = group_list\n",
    "    ind_feature['2nd 3rd pronouns'] = other_list\n",
    "\n",
    "    return ind_feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relational Features\n",
    "\n",
    "This portion of code extract the multi-sourced features from two dataframes (one is unreliable dataset that text that is evaluated, one for reliable dataset as reference news of evaluation).\n",
    "\n",
    "Restrictions: Two provided datasets must have the same number of data and have same feature and name. For better use, it is recommended to use the news/texts that have same topics.\n",
    "\n",
    "How to use: Place the datasets that consists of statements and feature values in a folder and put the name or path of the datasets in news1 and news2 arguments of multi_source_FE() definition.\n",
    "            news1 should be the dataset of referencing articles, and news2 should be the dataset of testing texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract each feature values for each data in the same row (one-to-one). List contains\n",
    "# the extracted feature values related to texts. Ex. feature_list[0] = all feature values of first statement\n",
    "# In case of there is null in the reference data, use two next reference data\n",
    "\n",
    "def one_to_one_dif(text, ref):\n",
    "    feature_list = []\n",
    "    feature = 0\n",
    "    for i in range (len(text)):\n",
    "        try:\n",
    "            feature = (float(text[i]) - float(ref[i]))\n",
    "        except:\n",
    "            try:\n",
    "                feature = (float(text[i]) - float(ref[i+2]))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        feature_list.append(round(feature, 2))\n",
    "    return feature_list\n",
    "    \n",
    "# Subtract each feature values for each data in the same row and repeat it with different references.(one-to-many)\n",
    "# Then, average the difference. List contains the extracted feature values related to texts.\n",
    "# Ex. final_list[0] = all feature values of first statement\n",
    "# In case of there is null in the reference data, use two next reference data\n",
    "\n",
    "def one_to_many_dif(text, ref):\n",
    "    avg_list = []\n",
    "    final_list = []\n",
    "    for i in range(len(text)):\n",
    "        for j in range(len(ref)):\n",
    "            try:\n",
    "                feature_val = float(text[i]) - float(ref[j])\n",
    "            except:\n",
    "                try:\n",
    "                    feature_val = float(text[i]) - float(ref[j+2])\n",
    "                except:\n",
    "                    pass\n",
    "            avg_list.append(feature_val)\n",
    "        avg = round(mean(avg_list), 2)\n",
    "        final_list.append(avg)\n",
    "    return final_list\n",
    "    \n",
    "    \n",
    "# Input: news1 (String), news2 (String), outFile (String), startFColumn (integer)\n",
    "# Description: Read the data from news1 (reliable) and news2 (unreliable), and put the data in two lists. Then, subtract the news1 values in each column from news2 values.\n",
    "#              The subtraction starts from startFColumn until the end of the .csv file. Next, the results will be saved in the file with given name or path from user (outFile)\n",
    "#\n",
    "# Return: New DataFrame ('MS_features')\n",
    "\n",
    "def multi_source_FE(text, ref):\n",
    "\n",
    "    # Saving original headers in header\n",
    "    header = list(text)\n",
    "    \n",
    "    # Only feature values\n",
    "    cols = [col for col in text.columns if col not in ['Statement', 'Label']]\n",
    "    \n",
    "    # Assign data of the testing text and referencing text in data1 and data2\n",
    "    if(text.equals(ref)):\n",
    "        ref = text.shift(periods = 1)\n",
    "        ref.iloc[0] = text.iloc[len(text)-1]\n",
    "    \n",
    "    state_text = text['Statement']\n",
    "    state_ref = ref['Statement']\n",
    "    label_text = text['Label']\n",
    "    data_text = text[cols]\n",
    "    data_ref = ref[cols]\n",
    "\n",
    "    feature_num = len(data_text.keys())\n",
    "\n",
    "\n",
    "    # Create local lists, dataframe that are used later in this definition.\n",
    "    df = pd.DataFrame()\n",
    "    sub = pd.DataFrame()\n",
    "    avg_sub = pd.DataFrame()\n",
    "    text = []\n",
    "    ref = []\n",
    "    total_list = []\n",
    "    new_total_list = []\n",
    "    \n",
    "    # Loop through the data for subtraction\n",
    "    for i in data_text.keys():\n",
    "        sub[i + \"- sub\"] = one_to_one_dif(data_text[i], data_ref[i])\n",
    "        avg_sub[i + \"- avg sub\"] = one_to_many_dif(data_text[i], data_ref[i])\n",
    "    \n",
    "    # Creating dataframe with multi-sourced features\n",
    "    df['Text'] = state_text\n",
    "    df['Reference'] = state_ref\n",
    "    df['Label'] = label_text\n",
    "    \n",
    "    # Concatenate the text, reference and features, then drop null values\n",
    "    df1 = pd.concat([df, data_text, sub, avg_sub], axis = 1)\n",
    "    df1 = df1.dropna(how = 'any')\n",
    "    \n",
    "    return df1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Analyzation\n",
    "\n",
    "This portion of code is for evaluating existing features on redundancy/irrelevancy by preliminary graph analysis of feature value distributions, and if necessary, transforming the distributions. Majority of methods used in this notebook is based on:\n",
    "\n",
    "https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python\n",
    "other resources:\n",
    "\n",
    "intro to feature selection: https://quantdare.com/what-is-the-difference-between-feature-extraction-and-feature-selection/\n",
    "feature selection method: https://www.datacamp.com/community/tutorials/feature-selection-python\n",
    "feature selection tools: https://scikit-learn.org/stable/modules/feature_selection.html\n",
    "graph usage in representing data: https://365datascience.com/chart-types-and-how-to-select-the-right-one/\n",
    "Issues:\n",
    "\n",
    "\"The most common way to assess linearity is to examine scatter plots and search for linear patterns. If patterns are not linear, it would be worthwhile to explore data transformations.\" reliability have 2 discrete categories (reliable and unreliable), how to do bivariate analysis? can't use scatter plot. heat map doesn't seem to work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>deeper analysis on selected features<!h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_setup(topic):\n",
    "    topic_list = topic.split(',')\n",
    "    \n",
    "    if len(topic_list) is 1:\n",
    "        if(topic in subject_list):\n",
    "            data = pd.read_csv(f'./feature_data/{topic}.csv')\n",
    "            reference = setup_data('reference.csv', topic, 1)\n",
    "    \n",
    "    else:\n",
    "        data = pd.DataFrame()\n",
    "        reference = pd.DataFrame()\n",
    "        for topics in topic_list:\n",
    "            if (topics in subject_list):\n",
    "                rel = pd.read_csv(f'./feature_data/{topics}.csv')\n",
    "                data = pd.concat([data, rel], ignore_index = True)\n",
    "                ref = setup_data('reference.csv', topics, 1)\n",
    "                reference = pd.concat([reference, ref], ignore_index = True)\n",
    "\n",
    "    reference_data = feature_extract(reference)\n",
    "    return data, reference_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with Machine Learning\n",
    "\n",
    "Using chosen features, the news data were tested with machine learning algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_train(data):    \n",
    "    feature_headings = [col for col in data.columns if col not in ['Unnamed: 0', 'Text', 'Reference']]\n",
    "\n",
    "    X = data[feature_headings].drop(data[feature_headings].columns[0], axis=1).abs()\n",
    "    y = data[\"Label\"]\n",
    "    \n",
    "    #anova\n",
    "    n = 20\n",
    "    bestfeatures = SelectKBest(score_func=f_classif, k=n)\n",
    "    fit = bestfeatures.fit(X,y)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "    featureScores.columns = ['Features','Score']  #naming the dataframe columns\n",
    "    selectedFeatures = featureScores.nlargest(n,'Score')['Features']\n",
    "    \n",
    "    X = X[selectedFeatures]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "    #print(X_train)\n",
    "\n",
    "    # ANOVA SVM-C\n",
    "    # 1) anova filter, take 3 best ranked features\n",
    "    anova_filter = SelectKBest(f_regression, k=n)\n",
    "    # 2) svm\n",
    "    clf = svm.LinearSVC()\n",
    "\n",
    "    anova_svm = make_pipeline(anova_filter, clf)\n",
    "    anova_svm.fit(X_train, y_train)\n",
    "    y_pred = anova_svm.predict(X_test)\n",
    "    #print(y_pred)\n",
    "    #print(y_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    #print('accuracy: ', accuracy)\n",
    "\n",
    "    #print(classification_report(y_test, y_pred))\n",
    "\n",
    "    coef = anova_svm[:-1].inverse_transform(anova_svm['linearsvc'].coef_)\n",
    "    #print(coef)\n",
    "    \n",
    "    return accuracy, anova_svm, selectedFeatures\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = []\n",
    "\n",
    "for a in pickle.load(open('./news_data/reliable.csv', 'rb')).keys():\n",
    "    subject_list.append(a)\n",
    "for a in pickle.load(open('./news_data/unreliable.csv', 'rb')).keys():\n",
    "    subject_list.append(a)\n",
    "for a in pickle.load(open('./news_data/reference.csv', 'rb')).keys():\n",
    "    subject_list.append(a)\n",
    "subject_list = set(subject_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drugs\n",
      "food-safety\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-8bca5951b383>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#data.to_csv(f'./feature_data/{subject}.csv')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mML_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0macc_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-dbc6fc3f7117>\u001b[0m in \u001b[0;36mML_train\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mbestfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf_classif\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbestfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mdfscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mdfcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \"\"\"\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n",
      "\u001b[1;32mC:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maux\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "\n",
    "for subject in subject_list:\n",
    "    print(subject)\n",
    "    data, ref = ML_setup(subject)\n",
    "    #data.to_csv(f'./feature_data/{subject}.csv')\n",
    "    \n",
    "    acc, model, features = ML_train(data)\n",
    "    acc_list.append(round(acc, 2))\n",
    "print(acc_list)\n",
    "print(mean(acc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_machine(statement, topic, label = 1):\n",
    "    topic_list = topic.split(',')\n",
    "    data, reference = ML_setup(topic)\n",
    "    accuracy, model, features = ML_train(data)\n",
    "    statements = pd.DataFrame([statement], columns = ['description'])\n",
    "    statements['label'] = label\n",
    "    feature = feature_extract(statements)\n",
    "    feature = multi_source_FE(feature, reference)\n",
    "    \n",
    "    return model.predict(feature[features])\n",
    "\n",
    "#print(final_machine(\"Video shows Joe Biden saying “we can only re-elect Donald Trump.”\", 'elections'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "immigration\n",
      "jobs\n",
      "military,veterans,voting-record\n",
      "medicare,message-machine-2012,campaign-advertising\n",
      "campaign-finance,legal-issues,campaign-advertising\n",
      "federal-budget,pensions,retirement\n",
      "county-budget,county-government,education,taxes\n",
      "economy,stimulus\n",
      "gays-and-lesbians,marriage\n",
      "foreign-policy\n",
      "elections\n",
      "ethics,message-machine\n",
      "environment\n",
      "federal-budget,military,poverty\n",
      "city-government,county-government,unions\n",
      "education,jobs\n",
      "labor,state-budget\n",
      "government-efficiency,government-regulation,polls\n",
      "health-care\n",
      "economy,history\n",
      "crime,gays-and-lesbians,sexuality\n",
      "elections\n",
      "immigration\n",
      "drugs,health-care,marijuana\n",
      "jobs,state-budget\n",
      "sotomayor-nomination,supreme-court\n",
      "foreign-policy\n",
      "education,state-budget\n",
      "climate-change,energy\n",
      "health-care,military\n",
      "congress,supreme-court\n",
      "crime,criminal-justice\n",
      "baseball,recreation\n",
      "message-machine,campaign-advertising\n",
      "elections\n",
      "health-care,history\n",
      "health-care\n",
      "abortion,legal-issues,women\n",
      "economy,financial-regulation\n",
      "states,taxes\n",
      "debates,health-care\n",
      "military,states\n",
      "debates,elections,polls\n",
      "environment\n",
      "health-care\n",
      "health-care\n",
      "terrorism\n",
      "economy,history,income,workers\n",
      "transportation\n",
      "abortion,health-care,legal-issues,women\n",
      "economy,jobs\n",
      "guns\n",
      "consumer-safety,public-safety,technology,transportation\n",
      "economy,immigration\n",
      "children,foreign-policy,immigration,legal-issues\n",
      "education,state-budget\n",
      "candidates-biography,state-budget\n",
      "abortion\n",
      "census\n",
      "immigration\n",
      "crime,criminal-justice,federal-budget,legal-issues\n",
      "foreign-policy,iraq,terrorism\n",
      "candidates-biography\n",
      "bankruptcy,debt\n",
      "health-care\n",
      "deficit,economy,taxes\n",
      "medicare,social-security\n",
      "economy,federal-budget,stimulus\n",
      "energy\n",
      "job-accomplishments,jobs\n",
      "bipartisanship,congress,congressional-rules,job-accomplishments,voting-record\n",
      "candidates-biography,foreign-policy,military\n",
      "state-finances,taxes\n",
      "deficit\n",
      "congressional-rules,federal-budget,health-care\n",
      "energy,environment,housing,recreation\n",
      "children,diversity\n",
      "federal-budget,infrastructure,message-machine,transportation,voting-record\n",
      "education,jobs,taxes\n",
      "corrections-and-updates,elections,legal-issues\n",
      "education\n",
      "elections,water\n",
      "crime,job-accomplishments\n",
      "federal-budget\n",
      "candidates-biography,county-budget,county-government\n",
      "occupy-wall-street\n",
      "energy,foreign-policy,nuclear\n",
      "transportation\n",
      "civil-rights,immigration,privacy,technology\n",
      "message-machine,taxes\n",
      "economy,health-care,workers\n",
      "city-budget,crime,job-accomplishments\n",
      "transportation\n",
      "stimulus\n",
      "economy\n",
      "elections\n",
      "health-care,public-health\n",
      "transportation\n",
      "state-budget,weather\n",
      "immigration\n",
      "history\n",
      "crime\n",
      "economy,history,income,pundits,taxes\n",
      "florida,foreign-policy\n",
      "climate-change,environment\n",
      "islam,terrorism\n",
      "women\n",
      "afghanistan,terrorism\n",
      "education,foreign-policy\n",
      "history\n",
      "debt,deficit\n",
      "abortion\n",
      "economy,jobs,market-regulation\n",
      "environment,government-regulation\n",
      "health-care,pundits\n",
      "education,sports\n",
      "bipartisanship,candidates-biography\n",
      "income\n",
      "guns,message-machine-2012\n",
      "income,jobs,message-machine-2012,taxes\n",
      "message-machine,public-safety,taxes,technology\n",
      "job-accomplishments,message-machine-2012,state-budget,state-finances\n",
      "history,polls\n",
      "health-care,history\n",
      "education\n",
      "government-regulation,job-accomplishments,jobs,labor,unions,workers\n",
      "message-machine,campaign-advertising\n",
      "bush-administration,pundits,recreation\n",
      "economy,job-accomplishments,jobs\n",
      "taxes\n",
      "abortion,pundits\n",
      "animals,candidates-biography,pundits\n",
      "animals,history\n",
      "medicare,retirement\n",
      "gambling\n",
      "voting-record\n",
      "candidates-biography,china,climate-change,economy,energy,environment,history,science\n",
      "children,education,state-budget\n",
      "criminal-justice,sports\n",
      "afghanistan,bush-administration,candidates-biography,ethics,foreign-policy,homeland-security,human-rights,iraq,public-safety,terrorism\n",
      "jobs,message-machine-2012\n",
      "iraq\n",
      "crime\n",
      "deficit\n",
      "climate-change,environment\n",
      "crime,legal-issues\n",
      "bipartisanship,debt,deficit,federal-budget\n",
      "health-care\n",
      "education,state-budget,unions\n",
      "candidates-biography\n",
      "city-government,gays-and-lesbians,government-regulation,public-safety\n",
      "federal-budget,polls,taxes\n",
      "federal-budget,social-security\n",
      "crime,government-regulation,guns\n",
      "state-budget\n",
      "elections,history\n",
      "candidates-biography\n",
      "families,income,poverty\n",
      "guns\n",
      "foreign-policy,history,new-hampshire-2012\n",
      "children,families,health-care,women\n",
      "education,state-budget,state-finances\n",
      "county-government\n",
      "climate-change,environment\n",
      "state-budget\n",
      "job-accomplishments\n",
      "criminal-justice\n",
      "energy,foreign-policy\n",
      "education\n",
      "job-accomplishments\n",
      "taxes\n",
      "taxes\n",
      "diversity,economy,jobs\n",
      "health-care,medicaid\n",
      "jobs\n",
      "gambling\n",
      "health-care\n",
      "candidates-biography\n",
      "health-care\n",
      "foreign-policy\n",
      "polls\n",
      "education\n",
      "criminal-justice,states\n",
      "abortion,crime\n",
      "agriculture,taxes\n",
      "elections\n",
      "cap-and-trade,climate-change\n",
      "education\n",
      "deficit,job-accomplishments,message-machine-2012,state-budget,state-finances\n",
      "federal-budget\n",
      "nightlife\n",
      "economy,foreign-policy,public-health\n",
      "foreign-policy,nuclear\n",
      "candidates-biography\n",
      "diversity,history\n",
      "economy\n",
      "drugs,guns,legal-issues\n",
      "campaign-finance,legal-issues,women\n",
      "health-care\n",
      "civil-rights,diversity,gays-and-lesbians,jobs,workers\n",
      "welfare\n",
      "economy,government-efficiency,jobs\n",
      "candidates-biography,crime,drugs,health-care,legal-issues,marijuana,public-health\n",
      "state-budget,taxes\n",
      "government-regulation,guns,legal-issues,public-health,public-safety,recreation,market-regulation,states\n",
      "immigration\n",
      "children,education,state-budget,states\n",
      "education\n",
      "health-care,medicare\n",
      "marriage,poverty\n",
      "nuclear\n",
      "polls\n",
      "taxes\n",
      "environment,jobs\n",
      "federal-budget\n",
      "abortion\n",
      "candidates-biography\n",
      "history,labor,women,workers\n",
      "economy,immigration,poverty,welfare\n",
      "social-security,taxes\n",
      "jobs,labor,states\n",
      "energy\n",
      "children,families,marriage,poverty\n",
      "economy,message-machine,voting-record\n",
      "guns,legal-issues,supreme-court\n",
      "jobs,state-budget\n",
      "jobs\n",
      "taxes\n",
      "state-budget,state-finances,taxes\n",
      "federal-budget\n",
      "taxes\n",
      "job-accomplishments\n",
      "federal-budget,pundits,taxes,abc-news-week\n",
      "economy,housing\n",
      "federal-budget\n",
      "economy,income\n",
      "economy,jobs,stimulus,workers\n",
      "candidates-biography,foreign-policy,nuclear\n",
      "education\n",
      "education,government-efficiency\n",
      "civil-rights,guns,legal-issues\n",
      "state-budget\n",
      "immigration\n",
      "foreign-policy,message-machine-2012,military,terrorism\n",
      "foreign-policy,terrorism\n",
      "debt,deficit,state-budget\n",
      "guns\n",
      "economy,federal-budget,jobs,stimulus\n",
      "immigration\n",
      "housing\n",
      "economy,jobs,workers\n",
      "immigration\n",
      "environment,jobs\n",
      "bush-administration,china,job-accomplishments,trade\n",
      "health-care,pundits\n",
      "guns\n",
      "foreign-policy\n",
      "crime\n",
      "public-health,water\n",
      "job-accomplishments\n",
      "crime,education,public-safety,state-budget\n",
      "congress,congressional-rules,corrections-and-updates\n",
      "candidates-biography\n",
      "corporations,income,taxes\n",
      "education,federal-budget\n",
      "health-care,jobs,message-machine-2012\n",
      "sports\n",
      "federal-budget,state-budget,stimulus,transportation\n",
      "health-care,military,abc-news-week\n",
      "economy,states\n",
      "health-care,retirement\n",
      "iraq\n",
      "crime,criminal-justice,immigration\n",
      "candidates-biography,ethics\n",
      "abortion,health-care\n",
      "transportation\n",
      "health-care\n",
      "iraq\n",
      "campaign-finance,legal-issues\n",
      "job-accomplishments\n",
      "economy,jobs\n",
      "congress,guns\n",
      "small-business\n",
      "health-care,income\n",
      "climate-change,energy,environment,foreign-policy,gas-prices\n",
      "abortion,health-care,public-health\n",
      "job-accomplishments,message-machine-2012,campaign-advertising,voting-record\n",
      "foreign-policy,religion,terrorism\n",
      "foreign-policy\n",
      "elections\n",
      "federal-budget,health-care\n",
      "health-care\n",
      "city-government,ethics\n",
      "environment,federal-budget,market-regulation\n",
      "congressional-rules,trade\n",
      "corporations,economy\n",
      "public-safety\n",
      "energy,environment\n",
      "energy\n",
      "afghanistan\n",
      "elections\n"
     ]
    }
   ],
   "source": [
    "train = read_data('train.tsv')\n",
    "test = read_data('test.tsv')\n",
    "valid = read_data('valid.tsv')\n",
    "\n",
    "result_list = []\n",
    "\n",
    "correct = 0\n",
    "wrong = 0\n",
    "for i in range(len(test)):\n",
    "    line = test.iloc[i]\n",
    "    try:\n",
    "        print(line['topic'])\n",
    "        result = final_machine(line['description'], line['topic'], line['label'])\n",
    "        if(result == int(line['label'])):\n",
    "            correct = correct + 1\n",
    "        elif(result != int(line['label'])):\n",
    "            wrong = wrong + 1\n",
    "        result_list.append(result)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "print('correct: ', correct)\n",
    "print('wrong: ', wrong)\n",
    "        \n",
    "print(result_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
